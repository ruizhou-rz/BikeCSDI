{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRmF88a5uqpF"
      },
      "source": [
        "Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bevj3XMuqJL",
        "outputId": "da6d55ea-fb79-40ab-86d7-f1fdd14b4126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.10/dist-packages (2.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.1)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric category_encoders\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "drive.mount(\"/content/drive/\")\n",
        "os.chdir(\"/content/drive/MyDrive/BikeCSDI/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypIiTX85b9nn"
      },
      "source": [
        "Import & Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBXL3uV2b9QD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch.optim import Adam\n",
        "import category_encoders as ce\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import yaml\n",
        "import re\n",
        "import numpy as np\n",
        "import typing as ty\n",
        "import torch.nn.init as nn_init\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "bike_components = {\n",
        "    \"Seat Tube\": [\"Seat tube length\", \"Seat tube extension2\", \"Seat tube diameter\", \"Seatpost setback\", \"Seatpost LENGTH\", \"Stack\", \"Lower stack height\", \"Upper stack height\"],\n",
        "    \"Head Tube\": [\"Head tube upper extension2\", \"Head angle\", \"Head tube lower extension2\", \"Head tube diameter\"],\n",
        "    \"Top Tube\": [\"Top tube rear diameter\", \"Top tube front diameter\"],\n",
        "    \"Down Tube\": [\"Down tube front diameter\", \"Down tube rear diameter\"],\n",
        "    \"Chain Stay\": [\"CHAINSTAYAUXrearDIAMETER\", \"Chain stay horizontal diameter\", \"Chain stay position on BB\", \"Chain stay taper\", \"Chain stay back diameter\", \"Chain stay vertical diameter\"],\n",
        "    \"Seat Stay\": [\"Seat stay junction0\", \"Seat stay bottom diameter\", \"SEATSTAY_HF\", \"SEATSTAY_HR\", \"SEATSTAYTAPERLENGTH\"],\n",
        "    \"Fork\": [\"FORK0R\", \"FORK0L\"],\n",
        "    \"Saddle\": [\"Saddle P\", \"Saddle thickness\", \"Saddle angle\", \"Saddle J\", \"Saddle H\", \"Saddle E\", \"SADDLETIPtoMIDDLE\", \"Saddle length\"],\n",
        "    \"Wheel\": [\"Wheel width rear\", \"Wheel width front\", \"Wheel diameter front\", \"Wheel diameter rear\", \"SPOKES composite front\", \"SPOKES front\", \"SPOKES rear\", \"SPOKES composite rear\", \"ERD rear\", \"ERD front\"],\n",
        "    \"Handle\": [\"Road bar reach\", \"Road bar drop\", \"Brake lever position\", \"Bullhorn angle\", \"HBAREXTEND\", \"Handlebar angle\", \"MtnBar angle\", \"HBARTHETA\", \"Pedal width\", \"Stem angle\", \"Stem length\"],\n",
        "    \"BB\": [\"BB textfield\", \"BB length\", \"BB diameter\"],\n",
        "    }\n",
        "\n",
        "bike_edge = torch.tensor([[0, 0, 0, 1, 1, 1, 1, 3, 3, 4, 4, 4, 5, 6], [2, 5, 7, 2, 3, 6, 9, 6, 10, 5, 8, 10, 8, 8]])\n",
        "\n",
        "config = {\n",
        "    \"train\": {\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 400,\n",
        "        \"lr\": 4e-4,\n",
        "    },\n",
        "    \"diffusion\": {\n",
        "        \"layers\": 4,\n",
        "        \"channels\": 128,\n",
        "        \"nheads\": 4,\n",
        "        \"diffusion_embedding_dim\": 128,\n",
        "        \"beta_start\": 0.0001,\n",
        "        \"beta_end\": 0.5,\n",
        "        \"num_steps\": 100,\n",
        "        \"schedule\": \"quad\",\n",
        "        \"mixed\": True,\n",
        "        \"token_emb_dim\": 8,\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"is_unconditional\": 0,\n",
        "        \"feature_emb\": 8,\n",
        "        \"time_emb\": 128,\n",
        "        \"target_strategy\": \"random\",\n",
        "        \"mixed\": True,\n",
        "        \"token_emb_dim\": 8,\n",
        "        \"graph_cond_dim\": 32,\n",
        "        \"test_missing_ratio\": 0.1,\n",
        "        \"graph_input_dim\": 16,\n",
        "        \"graph_hidden_dim\": 32,\n",
        "        \"graph_output_dim\": 32,\n",
        "    },\n",
        "  }\n",
        "\n",
        "seed = 4096\n",
        "\n",
        "nfold = 100\n",
        "\n",
        "nsample = 5\n",
        "\n",
        "masked_features = []\n",
        "\n",
        "timepoints = 182\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQkYY1ITkMe7"
      },
      "source": [
        "GraphCSDI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7rcmJWSkI0D"
      },
      "outputs": [],
      "source": [
        "def get_torch_trans(heads=8, layers=1, channels=64):\n",
        "    encoder_layer = nn.TransformerEncoderLayer(\n",
        "        d_model=channels, nhead=heads, dim_feedforward=64, activation=\"gelu\"\n",
        "    )\n",
        "    return nn.TransformerEncoder(encoder_layer, num_layers=layers)\n",
        "\n",
        "\n",
        "def Conv1d_with_init(in_channels, out_channels, kernel_size):\n",
        "    layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
        "    # Weight initialization\n",
        "    nn.init.kaiming_normal_(layer.weight)\n",
        "    return layer\n",
        "\n",
        "\n",
        "class DiffusionEmbedding(nn.Module):\n",
        "    def __init__(self, num_steps, embedding_dim=128, projection_dim=None):\n",
        "        super().__init__()\n",
        "        if projection_dim is None:\n",
        "            projection_dim = embedding_dim\n",
        "        self.register_buffer(\n",
        "            \"embedding\",\n",
        "            self._build_embedding(num_steps, embedding_dim / 2),\n",
        "            persistent=False,\n",
        "        )\n",
        "        self.projection1 = nn.Linear(embedding_dim, projection_dim)\n",
        "        self.projection2 = nn.Linear(projection_dim, projection_dim)\n",
        "\n",
        "    def forward(self, diffusion_step):\n",
        "        x = self.embedding[diffusion_step]\n",
        "        x = self.projection1(x)\n",
        "        x = F.silu(x)\n",
        "        x = self.projection2(x)\n",
        "        x = F.silu(x)\n",
        "        return x\n",
        "\n",
        "    # t_embedding(t). The embedding dimension is 128 in total for every time step t.\n",
        "    def _build_embedding(self, num_steps, dim=64):\n",
        "        steps = torch.arange(num_steps).unsqueeze(1)  # (T,1)\n",
        "        frequencies = 10.0 ** (torch.arange(dim) / (dim - 1) * 4.0).unsqueeze(\n",
        "            0\n",
        "        )  # (1,dim)\n",
        "        table = steps * frequencies  # (T,dim)\n",
        "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)  # (T,dim*2)\n",
        "        return table\n",
        "\n",
        "\n",
        "class diff_CSDI(nn.Module):\n",
        "    def __init__(self, config, inputdim=2):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.channels = config[\"channels\"]\n",
        "\n",
        "        self.diffusion_embedding = DiffusionEmbedding(\n",
        "            num_steps=config[\"num_steps\"],\n",
        "            embedding_dim=config[\"diffusion_embedding_dim\"],\n",
        "        )\n",
        "\n",
        "        self.token_emb_dim = config[\"token_emb_dim\"] if config[\"mixed\"] else 1\n",
        "        inputdim = 2 * self.token_emb_dim\n",
        "\n",
        "        self.input_projection = Conv1d_with_init(inputdim, self.channels, 1)\n",
        "        self.output_projection1 = Conv1d_with_init(self.channels, self.channels, 1)\n",
        "        self.output_projection2 = Conv1d_with_init(self.channels, self.token_emb_dim, 1)\n",
        "        nn.init.zeros_(self.output_projection2.weight)\n",
        "\n",
        "        self.residual_layers = nn.ModuleList(\n",
        "            [\n",
        "                ResidualBlock(\n",
        "                    side_dim=config[\"side_dim\"],\n",
        "                    channels=self.channels,\n",
        "                    diffusion_embedding_dim=config[\"diffusion_embedding_dim\"],\n",
        "                    nheads=config[\"nheads\"],\n",
        "                )\n",
        "                for _ in range(config[\"layers\"])\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond_info, diffusion_step):\n",
        "        B, inputdim, K, L = x.shape\n",
        "\n",
        "        x = x.reshape(B, inputdim, K * L)\n",
        "        x = self.input_projection(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.reshape(B, self.channels, K, L)\n",
        "\n",
        "        diffusion_emb = self.diffusion_embedding(diffusion_step)\n",
        "\n",
        "        skip = []\n",
        "        for layer in self.residual_layers:\n",
        "            x, skip_connection = layer(x, cond_info, diffusion_emb)\n",
        "            skip.append(skip_connection)\n",
        "\n",
        "        x = torch.sum(torch.stack(skip), dim=0) / math.sqrt(len(self.residual_layers))\n",
        "        x = x.reshape(B, self.channels, K * L)\n",
        "\n",
        "        x = self.output_projection1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.output_projection2(x)\n",
        "        if self.config[\"mixed\"]:\n",
        "            x = x.permute(0, 2, 1)\n",
        "            x = x.reshape(B, K, L * self.token_emb_dim)\n",
        "        else:\n",
        "            x = x.reshape(B, K, L)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, side_dim, channels, diffusion_embedding_dim, nheads):\n",
        "        super().__init__()\n",
        "        self.diffusion_projection = nn.Linear(diffusion_embedding_dim, channels)\n",
        "        self.cond_projection = Conv1d_with_init(side_dim, 2 * channels, 1)\n",
        "        self.mid_projection = Conv1d_with_init(channels, 2 * channels, 1)\n",
        "        self.output_projection = Conv1d_with_init(channels, 2 * channels, 1)\n",
        "\n",
        "        # Temporal Transformer layer\n",
        "        self.time_layer = get_torch_trans(heads=nheads, layers=1, channels=channels)\n",
        "        # Feature Transformer layer\n",
        "        self.feature_layer = get_torch_trans(heads=nheads, layers=1, channels=channels)\n",
        "\n",
        "    def forward_time(self, y, base_shape):\n",
        "        B, channel, K, L = base_shape\n",
        "        if L == 1:\n",
        "            return y\n",
        "        y = y.reshape(B, channel, K, L).permute(0, 2, 1, 3).reshape(B * K, channel, L)\n",
        "        # (B*K, C, L) -> (L, B*K, C) -> (B*K, C, L)\n",
        "        # input shape for transformerencoder: [seq, batch, emb]\n",
        "        y = self.time_layer(y.permute(2, 0, 1)).permute(1, 2, 0)\n",
        "        y = y.reshape(B, K, channel, L).permute(0, 2, 1, 3).reshape(B, channel, K * L)\n",
        "        return y\n",
        "\n",
        "    def forward_feature(self, y, base_shape):\n",
        "        B, channel, K, L = base_shape\n",
        "        if K == 1:\n",
        "            return y\n",
        "        y = y.reshape(B, channel, K, L).permute(0, 3, 1, 2).reshape(B * L, channel, K)\n",
        "        # (B*L, C, K) -> (K, B*L, C) -> (B*L, C, K)\n",
        "        y = self.feature_layer(y.permute(2, 0, 1)).permute(1, 2, 0)\n",
        "        y = y.reshape(B, L, channel, K).permute(0, 2, 3, 1).reshape(B, channel, K * L)\n",
        "        return y\n",
        "\n",
        "    def forward(self, x, cond_info, diffusion_emb):\n",
        "        B, channel, K, L = x.shape\n",
        "        base_shape = x.shape\n",
        "        x = x.reshape(B, channel, K * L)\n",
        "\n",
        "        # diffusion_emb is\n",
        "        diffusion_emb = self.diffusion_projection(diffusion_emb).unsqueeze(\n",
        "            -1\n",
        "        )  # (B,channel,1)\n",
        "        y = x + diffusion_emb\n",
        "\n",
        "        y = self.forward_time(y, base_shape)\n",
        "        y = self.forward_feature(y, base_shape)  # (B,channel,K*L)\n",
        "        y = self.mid_projection(y)  # (B,2*channel,K*L)\n",
        "\n",
        "        _, cond_dim, _, _ = cond_info.shape\n",
        "        cond_info = cond_info.reshape(B, cond_dim, K * L)\n",
        "        cond_info = self.cond_projection(cond_info)  # (B,2*channel,K*L)\n",
        "        y = y + cond_info\n",
        "\n",
        "        gate, filter = torch.chunk(y, 2, dim=1)\n",
        "        y = torch.sigmoid(gate) * torch.tanh(filter)  # (B,channel,K*L)\n",
        "        y = self.output_projection(y)\n",
        "\n",
        "        residual, skip = torch.chunk(y, 2, dim=1)\n",
        "        x = x.reshape(base_shape)\n",
        "        residual = residual.reshape(base_shape)\n",
        "        skip = skip.reshape(base_shape)\n",
        "        return (x + residual) / math.sqrt(2.0), skip\n",
        "\n",
        "\n",
        "class Tokenizer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_numerical: int,\n",
        "        categories: ty.Optional[ty.List[int]],\n",
        "        d_token: int,\n",
        "        bias: bool,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        d_bias = d_numerical + len(categories)\n",
        "        category_offsets = torch.tensor([0] + categories[:-1]).cumsum(0)\n",
        "        self.d_token = d_token\n",
        "        self.register_buffer(\"category_offsets\", category_offsets)\n",
        "        self.category_embeddings = nn.Embedding(sum(categories) + 1, self.d_token)\n",
        "        self.category_embeddings.weight.requires_grad = False\n",
        "        nn_init.kaiming_uniform_(self.category_embeddings.weight, a=math.sqrt(5))\n",
        "\n",
        "        self.weight = nn.Parameter(Tensor(d_numerical, self.d_token))\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "        self.bias = nn.Parameter(Tensor(d_bias, self.d_token)) if bias else None\n",
        "        nn_init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            nn_init.kaiming_uniform_(self.bias, a=math.sqrt(5))\n",
        "            self.bias.requires_grad = False\n",
        "\n",
        "    @property\n",
        "    def n_tokens(self) -> int:\n",
        "        return len(self.weight) + (\n",
        "            0 if self.category_offsets is None else len(self.category_offsets)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_num: Tensor, x_cat: ty.Optional[Tensor]) -> Tensor:\n",
        "        x_some = x_num if x_cat is None else x_cat\n",
        "        x_cat = x_cat.type(torch.int32)\n",
        "\n",
        "        assert x_some is not None\n",
        "        x = self.weight.T * x_num\n",
        "\n",
        "        if x_cat is not None:\n",
        "            x = x[:, np.newaxis, :, :]\n",
        "            x = x.permute(0, 1, 3, 2)\n",
        "            x = torch.cat(\n",
        "                [x, self.category_embeddings(x_cat + self.category_offsets[None])],\n",
        "                dim=2,\n",
        "            )\n",
        "        if self.bias is not None:\n",
        "            x = x + self.bias[None]\n",
        "\n",
        "        return x\n",
        "\n",
        "    def recover(self, Batch, d_numerical):\n",
        "        B, L, K = Batch.shape\n",
        "        L_new = int(L / self.d_token)\n",
        "        Batch = Batch.reshape(B, L_new, self.d_token)\n",
        "        Batch = Batch - self.bias\n",
        "\n",
        "        Batch_numerical = Batch[:, :d_numerical, :]\n",
        "        Batch_numerical = Batch_numerical / self.weight\n",
        "        Batch_numerical = torch.mean(Batch_numerical, 2, keepdim=False)\n",
        "\n",
        "        Batch_cat = Batch[:, d_numerical:, :]\n",
        "        new_Batch_cat = torch.zeros([Batch_cat.shape[0], Batch_cat.shape[1]])\n",
        "        for i in range(Batch_cat.shape[1]):\n",
        "            token_start = self.category_offsets[i] + 1\n",
        "            if i == Batch_cat.shape[1] - 1:\n",
        "                token_end = self.category_embeddings.weight.shape[0] - 1\n",
        "            else:\n",
        "                token_end = self.category_offsets[i + 1]\n",
        "            emb_vec = self.category_embeddings.weight[token_start : token_end + 1, :]\n",
        "            for j in range(Batch_cat.shape[0]):\n",
        "                distance = torch.norm(emb_vec - Batch_cat[j, i, :], dim=1)\n",
        "                nearest = torch.argmin(distance)\n",
        "                new_Batch_cat[j, i] = nearest + 1\n",
        "            new_Batch_cat = new_Batch_cat.to(Batch_numerical.device)\n",
        "        return torch.cat([Batch_numerical, new_Batch_cat], dim=1)\n",
        "\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "        self.output_proj = nn.Linear(output_dim, output_dim)\n",
        "        self.bn = nn.BatchNorm1d(output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.bn(F.relu(self.output_proj(x)))\n",
        "        return x\n",
        "\n",
        "class StructuralEmbedding(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim=16):\n",
        "    super().__init__()\n",
        "    self.proj = nn.Linear(input_dim, output_dim)\n",
        "    self.bn = nn.BatchNorm1d(output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.proj(x))\n",
        "    x = self.bn(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class GraphEmbedding(nn.Module):\n",
        "  def __init__(self, config, device):\n",
        "    super().__init__()\n",
        "    graph_input_dim, graph_hidden_dim, graph_output_dim = config[\"model\"][\"graph_input_dim\"], config[\"model\"][\"graph_hidden_dim\"], config[\"model\"][\"graph_output_dim\"]\n",
        "    self.proj = nn.ModuleDict({\n",
        "        component: StructuralEmbedding(len(bike_components[component]), graph_input_dim) for component in bike_components\n",
        "    })\n",
        "    self.gnn = GNNModel(graph_input_dim, graph_hidden_dim, graph_output_dim)\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self, batch):\n",
        "    graph_inputs = [self.proj[component](batch[component].to(self.device)) for component in bike_components]\n",
        "    graphs = [Data(x=torch.stack([graph_inputs[n][i] for n in range(len(graph_inputs))]), edge_index=bike_edge) for i in range(len(graph_inputs[0]))]\n",
        "    graph_batch = Batch.from_data_list(graphs).to(self.device)\n",
        "    graph_cond = self.gnn(graph_batch)  # (B, G)\n",
        "    return graph_cond\n",
        "\n",
        "\n",
        "class CSDI_base(nn.Module):\n",
        "    def __init__(self, target_dim, config, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.target_dim = target_dim\n",
        "\n",
        "        # load embedding vector dimension.\n",
        "        self.emb_feature_dim = config[\"model\"][\"feature_emb\"]\n",
        "        self.emb_time_dim = config[\"model\"][\"time_emb\"]\n",
        "        self.graph_cond_dim = config[\"model\"][\"graph_cond_dim\"]\n",
        "\n",
        "        self.emb_total_dim = self.emb_feature_dim + self.emb_time_dim + self.graph_cond_dim\n",
        "        self.graph_embed = GraphEmbedding(config, device)\n",
        "\n",
        "        self.is_unconditional = config[\"model\"][\"is_unconditional\"]\n",
        "        self.target_strategy = config[\"model\"][\"target_strategy\"]\n",
        "\n",
        "        # For categorical variables\n",
        "        self.mixed = config[\"model\"][\"mixed\"]\n",
        "\n",
        "        with open(\"./data/transformed_columns.pk\", \"rb\") as f:\n",
        "            cont_list, num_cate_list = pickle.load(f)\n",
        "\n",
        "        self.cont_list = cont_list\n",
        "        self.num_cate_list = num_cate_list\n",
        "\n",
        "        if self.mixed:\n",
        "            self.token_dim = config[\"model\"][\"token_emb_dim\"]\n",
        "\n",
        "            # set tokenizer\n",
        "            d_numerical = len(self.cont_list)\n",
        "            categories = self.num_cate_list\n",
        "            d_token = self.token_dim\n",
        "            token_bias = True\n",
        "\n",
        "            self.tokenizer = Tokenizer(d_numerical, categories, d_token, token_bias)\n",
        "\n",
        "        if self.is_unconditional == False:\n",
        "            self.emb_total_dim += 1  # for conditional mask\n",
        "\n",
        "        self.embed_layer = nn.Embedding(\n",
        "            num_embeddings=self.target_dim, embedding_dim=self.emb_feature_dim\n",
        "        )\n",
        "\n",
        "        config_diff = config[\"diffusion\"]\n",
        "        config_diff[\"side_dim\"] = self.emb_total_dim\n",
        "\n",
        "        input_dim = 1 if self.is_unconditional == True else 2\n",
        "        tot_feature_num = len(cont_list) + len(num_cate_list)\n",
        "        self.diffmodel = diff_CSDI(config_diff, input_dim)\n",
        "\n",
        "        # parameters for diffusion models\n",
        "        self.num_steps = config_diff[\"num_steps\"]\n",
        "        if config_diff[\"schedule\"] == \"quad\":\n",
        "            self.beta = (\n",
        "                np.linspace(\n",
        "                    config_diff[\"beta_start\"] ** 0.5,\n",
        "                    config_diff[\"beta_end\"] ** 0.5,\n",
        "                    self.num_steps,\n",
        "                )\n",
        "                ** 2\n",
        "            )\n",
        "        elif config_diff[\"schedule\"] == \"linear\":\n",
        "            self.beta = np.linspace(\n",
        "                config_diff[\"beta_start\"], config_diff[\"beta_end\"], self.num_steps\n",
        "            )\n",
        "\n",
        "        self.alpha_hat = 1 - self.beta\n",
        "        self.alpha = np.cumprod(self.alpha_hat)\n",
        "        self.alpha_torch = (\n",
        "            torch.tensor(self.alpha).float().to(self.device).unsqueeze(1).unsqueeze(1)\n",
        "        )\n",
        "\n",
        "    def get_randmask(self, observed_mask):\n",
        "        rand_for_mask = torch.rand_like(observed_mask) * observed_mask\n",
        "        rand_for_mask = rand_for_mask.reshape(len(rand_for_mask), -1)\n",
        "\n",
        "        for i in range(len(observed_mask)):\n",
        "            sample_ratio = np.random.rand()\n",
        "            num_observed = observed_mask[i].sum().item()\n",
        "            num_masked = round(num_observed * sample_ratio)\n",
        "            rand_for_mask[i][rand_for_mask[i].topk(num_masked).indices] = -1\n",
        "        cond_mask = (rand_for_mask > 0).reshape(observed_mask.shape).float()\n",
        "        return cond_mask\n",
        "\n",
        "    def time_embedding(self, pos, d_model=128):\n",
        "        pe = torch.zeros(pos.shape[0], pos.shape[1], d_model).to(self.device)\n",
        "        position = pos.unsqueeze(2)\n",
        "        div_term = 1 / torch.pow(\n",
        "            10000.0, torch.arange(0, d_model, 2).to(self.device) / d_model\n",
        "        )\n",
        "        pe[:, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, :, 1::2] = torch.cos(position * div_term)\n",
        "        return pe\n",
        "\n",
        "    def get_side_info(self, graph_features, observed_tp, cond_mask):\n",
        "        B, K, L = cond_mask.shape\n",
        "\n",
        "        graph_embed = self.graph_embed(graph_features)  # (B,Graph_emb)\n",
        "        graph_embed = graph_embed.unsqueeze(1).unsqueeze(1).expand(-1, L, K, -1)\n",
        "\n",
        "        time_embed = self.time_embedding(observed_tp, self.emb_time_dim)  # (B,L,emb)\n",
        "        time_embed = time_embed.unsqueeze(2).expand(-1, -1, K, -1)\n",
        "        feature_embed = self.embed_layer(\n",
        "            torch.arange(self.target_dim).to(self.device)\n",
        "        )  # (K,emb)\n",
        "        feature_embed = feature_embed.unsqueeze(0).unsqueeze(0).expand(B, L, -1, -1)\n",
        "        side_info = torch.cat([graph_embed, time_embed, feature_embed], dim=-1)  # (B,L,K,*)\n",
        "        side_info = side_info.permute(0, 3, 2, 1)  # (B,*,K,L)\n",
        "\n",
        "        if self.is_unconditional == False:\n",
        "            side_mask = cond_mask.unsqueeze(1)  # (B,1,K,L)\n",
        "            side_info = torch.cat([side_info, side_mask], dim=1)\n",
        "\n",
        "        return side_info\n",
        "\n",
        "    def calc_loss_valid(\n",
        "        self, observed_data, cond_mask, observed_mask, side_info, is_train\n",
        "    ):\n",
        "        loss_sum = 0\n",
        "        for t in range(self.num_steps):\n",
        "            loss = self.calc_loss(\n",
        "                observed_data, cond_mask, observed_mask, side_info, is_train, set_t=t\n",
        "            )\n",
        "            loss_sum += loss.detach()\n",
        "        return loss_sum / self.num_steps\n",
        "\n",
        "    def calc_loss(\n",
        "        self, observed_data, cond_mask, observed_mask, side_info, is_train, set_t=-1\n",
        "    ):\n",
        "        B, K, L = observed_data.shape\n",
        "        if is_train != 1:\n",
        "            t = (torch.ones(B) * set_t).long().to(self.device)\n",
        "        else:\n",
        "            t = torch.randint(0, self.num_steps, [B]).to(self.device)\n",
        "        current_alpha = self.alpha_torch[t]  # (B,1,1)\n",
        "        noise = torch.randn_like(observed_data)\n",
        "        # Perform forward step. Adding noise to all data.\n",
        "        noisy_data = (current_alpha**0.5) * observed_data + (\n",
        "            1.0 - current_alpha\n",
        "        ) ** 0.5 * noise\n",
        "        total_input = self.set_input_to_diffmodel(noisy_data, observed_data, cond_mask)\n",
        "        predicted = self.diffmodel(total_input, side_info, t)  # (B,K,L*token_dim)\n",
        "\n",
        "        target_mask = observed_mask - cond_mask\n",
        "        target_mask = torch.repeat_interleave(target_mask, self.token_dim, dim=2)\n",
        "        residual = (noise - predicted) * target_mask\n",
        "        num_eval = target_mask.sum()\n",
        "        loss = (residual**2).sum() / (num_eval if num_eval > 0 else 1)\n",
        "        return loss\n",
        "\n",
        "    def set_input_to_diffmodel(self, noisy_data, observed_data, cond_mask):\n",
        "\n",
        "        cond_mask = torch.repeat_interleave(cond_mask, self.token_dim, dim=2)\n",
        "\n",
        "        cond_obs = (cond_mask * observed_data).unsqueeze(1)\n",
        "        noisy_target = ((1 - cond_mask) * noisy_data).unsqueeze(1)\n",
        "        total_input = torch.cat([cond_obs, noisy_target], dim=1)  # (B,2,K,L)\n",
        "        B, old_input_dim, K, L = total_input.shape\n",
        "        total_input = total_input.reshape(\n",
        "            B, old_input_dim, K, int(L / self.token_dim), self.token_dim\n",
        "        )\n",
        "        total_input = total_input.permute(0, 1, 4, 2, 3)\n",
        "        total_input = total_input.reshape(\n",
        "            B, old_input_dim * self.token_dim, K, int(L / self.token_dim)\n",
        "        )\n",
        "\n",
        "        return total_input\n",
        "\n",
        "    def impute(self, observed_data, cond_mask, side_info, n_samples):\n",
        "\n",
        "        B, K, L = observed_data.shape\n",
        "        cond_mask = torch.repeat_interleave(cond_mask, self.token_dim, dim=2)\n",
        "\n",
        "        imputed_samples = torch.zeros(B, n_samples, K, L).to(self.device)\n",
        "        # Perform n_samples times of forward and backward pass for same input data.\n",
        "        for i in range(n_samples):\n",
        "            if self.is_unconditional == True:\n",
        "                noisy_obs = observed_data\n",
        "                noisy_cond_history = []\n",
        "                # perform T steps forward\n",
        "                for t in range(self.num_steps):\n",
        "                    noise = torch.randn_like(noisy_obs)\n",
        "                    noisy_obs = (self.alpha_hat[t] ** 0.5) * noisy_obs + self.beta[\n",
        "                        t\n",
        "                    ] ** 0.5 * noise\n",
        "                    noisy_cond_history.append(noisy_obs * cond_mask)\n",
        "\n",
        "            current_sample = torch.randn_like(observed_data)\n",
        "            # perform T steps backward\n",
        "            for t in range(self.num_steps - 1, -1, -1):\n",
        "                if self.is_unconditional == True:\n",
        "                    diff_input = (\n",
        "                        cond_mask * noisy_cond_history[t]\n",
        "                        + (1.0 - cond_mask) * current_sample\n",
        "                    )\n",
        "                    diff_input = diff_input.unsqueeze(1)  # (B,1,K,L)\n",
        "                else:\n",
        "                    # fix original x^{co} as condition\n",
        "                    cond_obs = (cond_mask * observed_data).unsqueeze(1)\n",
        "                    noisy_target = ((1 - cond_mask) * current_sample).unsqueeze(1)\n",
        "                    diff_input = torch.cat([cond_obs, noisy_target], dim=1)  # (B,2,K,L)\n",
        "                    B, old_input_dim, K, L = diff_input.shape\n",
        "                    diff_input = diff_input.reshape(\n",
        "                        B, old_input_dim, K, int(L / self.token_dim), self.token_dim\n",
        "                    )\n",
        "                    diff_input = diff_input.permute(0, 1, 4, 2, 3)\n",
        "                    diff_input = diff_input.reshape(\n",
        "                        B, old_input_dim * self.token_dim, K, int(L / self.token_dim)\n",
        "                    )\n",
        "\n",
        "                predicted = self.diffmodel(\n",
        "                    diff_input, side_info, torch.tensor([t]).to(self.device)\n",
        "                )  # (B,K,L)\n",
        "                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
        "                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
        "\n",
        "                current_sample = coeff1 * (current_sample - coeff2 * predicted)\n",
        "\n",
        "                if t > 0:\n",
        "                    noise = torch.randn_like(current_sample)\n",
        "                    sigma = (\n",
        "                        (1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]\n",
        "                    ) ** 0.5\n",
        "                    current_sample += sigma * noise\n",
        "            imputed_samples[:, i] = current_sample.detach()\n",
        "\n",
        "        return imputed_samples\n",
        "\n",
        "    def forward(self, batch, is_train=1):\n",
        "        (\n",
        "            observed_data,\n",
        "            observed_mask,\n",
        "            observed_tp,\n",
        "            gt_mask,\n",
        "            for_pattern_mask,\n",
        "            _,\n",
        "            graph_features,\n",
        "        ) = self.process_data(batch)\n",
        "\n",
        "        # In testing, using `gt_mask` (generated with fixed missing rate) as cond_mask.\n",
        "        # In training, generate random mask as cond_mask\n",
        "        if is_train == 0:\n",
        "            cond_mask = gt_mask\n",
        "        else:\n",
        "            cond_mask = self.get_randmask(observed_mask)\n",
        "\n",
        "        cond_mask[:, :, :self.graph_cond_dim] = True\n",
        "\n",
        "        side_info = self.get_side_info(graph_features, observed_tp, cond_mask)\n",
        "\n",
        "        # The main calculation procedures are in `self.calc_loss()`\n",
        "        loss_func = self.calc_loss if is_train == 1 else self.calc_loss_valid\n",
        "        return loss_func(observed_data, cond_mask, observed_mask, side_info, is_train)\n",
        "\n",
        "    def evaluate(self, batch, n_samples):\n",
        "        (\n",
        "            observed_data,\n",
        "            observed_mask,\n",
        "            observed_tp,\n",
        "            gt_mask,\n",
        "            _,\n",
        "            cut_length,\n",
        "            graph_features,\n",
        "        ) = self.process_data(batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # gt_mask: 0 for missing elements and manully maksed elements\n",
        "            cond_mask = gt_mask\n",
        "            # target_mask: 1 for manually masked elements\n",
        "            target_mask = observed_mask - cond_mask\n",
        "            side_info = self.get_side_info(graph_features, observed_tp, cond_mask)\n",
        "            samples = self.impute(observed_data, cond_mask, side_info, n_samples)\n",
        "\n",
        "        return samples, observed_data, target_mask, observed_mask\n",
        "\n",
        "\n",
        "class BikeGraphCSDI(CSDI_base):\n",
        "    def __init__(self, config, device, target_dim=1):\n",
        "        super().__init__(target_dim, config, device)\n",
        "\n",
        "    def process_data(self, batch):\n",
        "        # Insert K=1 axis. All mask now with shape (B, 1, L). L=# of attributes.\n",
        "        observed_data = batch[\"observed_data\"][:, np.newaxis, :]\n",
        "        observed_data = observed_data.to(self.device).float()\n",
        "        observed_data = self.tokenizer(\n",
        "            observed_data[:, :, self.cont_list],\n",
        "            observed_data[:, :, len(self.cont_list) :],\n",
        "        )\n",
        "        B, K, L, C = observed_data.shape\n",
        "        observed_data = observed_data.reshape(B, K, L * C)\n",
        "        observed_mask = batch[\"observed_mask\"][:, np.newaxis, :]\n",
        "        observed_mask = observed_mask.to(self.device).float()\n",
        "\n",
        "        gt_mask = batch[\"gt_mask\"][:, np.newaxis, :]\n",
        "        gt_mask = gt_mask.to(self.device).float()\n",
        "\n",
        "        observed_tp = batch[\"timepoints\"].to(self.device).float()\n",
        "\n",
        "        cut_length = torch.zeros(len(observed_data)).long().to(self.device)\n",
        "        for_pattern_mask = observed_mask\n",
        "\n",
        "        graph_features = batch[\"graph_features\"]\n",
        "\n",
        "        return (\n",
        "            observed_data,\n",
        "            observed_mask,\n",
        "            observed_tp,\n",
        "            gt_mask,\n",
        "            for_pattern_mask,\n",
        "            cut_length,\n",
        "            graph_features,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5opWrU8nzgT"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aja7sD7BnzHu"
      },
      "outputs": [],
      "source": [
        "def process_func(path: str, masked_features: list, encode=True, missing_ratio=0):\n",
        "\n",
        "    pd_data = pd.read_csv(path, header=0)\n",
        "    data = pd_data.iloc[:, 1:]\n",
        "    cat_list = []\n",
        "    for n, i in enumerate(data.columns):\n",
        "        if len(set(data[i])) <= 5 or type(data[i][0]) == str:\n",
        "            cat_list.append(n)\n",
        "    # Swap columns\n",
        "    temp_list = [i for i in range(data.shape[1]) if i not in cat_list]\n",
        "    temp_list.extend(cat_list)\n",
        "    new_cols_order = temp_list\n",
        "\n",
        "    data = data.reindex(columns=data.columns[new_cols_order])\n",
        "    column_index = {column: list(data.columns).index(column) for column in data.columns}\n",
        "    with open(\"./column_index.pk\", \"wb\") as f:\n",
        "      pickle.dump(column_index, f)\n",
        "    print(column_index)\n",
        "    # create two lists to store position\n",
        "    cont_list = [i for i in range(0, data.shape[1] - len(cat_list))]\n",
        "    cat_list = [i for i in range(len(cont_list), data.shape[1])]\n",
        "\n",
        "    observed_values = data.values\n",
        "    observed_masks = ~pd.isnull(data)\n",
        "    observed_masks = observed_masks.values\n",
        "\n",
        "    # In this section, obtain gt_masks\n",
        "    masks = observed_masks.copy()\n",
        "    # for each masked feature, mask the corresponding column of observed values.\n",
        "    if missing_ratio > 0:\n",
        "      for col in range(masks.shape[1]):\n",
        "        obs_indices = np.where(masks[:, col])[0]\n",
        "        miss_indices = np.random.choice(\n",
        "          obs_indices, (int)(len(obs_indices) * missing_ratio), replace=False\n",
        "        )\n",
        "        masks[miss_indices, col] = False\n",
        "    for col in masked_features:\n",
        "        masks[:, column_index[col]] = False\n",
        "    # gt_mask: 0 for missing elements and manully maksed elements\n",
        "    gt_masks = masks.reshape(observed_masks.shape)\n",
        "\n",
        "    # train-test split\n",
        "    indlist = np.arange(len(observed_values))\n",
        "    np.random.seed(seed + 1)\n",
        "    np.random.shuffle(indlist)\n",
        "    tmp_ratio = 1 / nfold\n",
        "    start = (int)((nfold - 1) * len(observed_values) * tmp_ratio)\n",
        "    end = (int)(nfold * len(observed_values) * tmp_ratio)\n",
        "    test_index = indlist[start:end]\n",
        "    remain_index = np.delete(indlist, np.arange(start, end))\n",
        "    np.random.shuffle(remain_index)\n",
        "    num_train = (int)(len(remain_index) * 1)\n",
        "    train_index = remain_index[:num_train]\n",
        "    valid_index = remain_index[num_train:]\n",
        "\n",
        "    num_cate_list = []\n",
        "    # set encoder here\n",
        "    encoder = ce.ordinal.OrdinalEncoder(cols=data.columns[cat_list])\n",
        "    encoder.fit(data)\n",
        "    new_df = encoder.transform(data)\n",
        "    # we now need to transform these masks to the new one, suitable for mixed data types.\n",
        "    cum_num_bits = 0\n",
        "    new_observed_masks = observed_masks.copy()\n",
        "    new_gt_masks = gt_masks.copy()\n",
        "\n",
        "    for index, col in enumerate(cat_list):\n",
        "        num_cate_list.append(new_df.iloc[:, col].nunique())\n",
        "        corresponding_cols = len(\n",
        "            [\n",
        "                s\n",
        "                for s in new_df.columns\n",
        "                if isinstance(s, str) and s.startswith(str(col) + \"_\")\n",
        "            ]\n",
        "        )\n",
        "        add_col_num = corresponding_cols\n",
        "        insert_col_obs = observed_masks[:, col]\n",
        "        insert_col_gt = gt_masks[:, col]\n",
        "\n",
        "        for i in range(add_col_num - 1):\n",
        "            observed_masks = np.insert(\n",
        "                new_observed_masks, cum_num_bits + col, insert_col_obs, axis=1\n",
        "            )\n",
        "            gt_masks = np.insert(\n",
        "                new_gt_masks, cum_num_bits + col, insert_col_gt, axis=1\n",
        "            )\n",
        "        cum_num_bits += add_col_num - 1\n",
        "\n",
        "    observed_values = new_df.values\n",
        "    observed_values = np.nan_to_num(observed_values)\n",
        "    observed_values = observed_values.astype(np.float32)\n",
        "\n",
        "    processed_data_path_norm = f\"./data/nfold-{nfold}-missing_ratio-{missing_ratio}_seed-{seed}_max-min_norm.pk\"\n",
        "    # Here we perform max-min normalization.\n",
        "    print(\n",
        "        \"--------------Dataset has not been normalized yet. Perform data normalization and store the mean value of each column.--------------\"\n",
        "    )\n",
        "    # data transformation after train-test split.\n",
        "    col_num = len(cont_list)\n",
        "    max_arr = np.zeros(col_num)\n",
        "    min_arr = np.zeros(col_num)\n",
        "    mean_arr = np.zeros(col_num)\n",
        "    for index, k in enumerate(cont_list):\n",
        "        # Using observed_mask to avoid counting missing values (now represented as 0)\n",
        "        obs_ind = observed_masks[train_index, k].astype(bool)\n",
        "        temp = observed_values[train_index, k]\n",
        "        max_arr[index] = max(temp[obs_ind])\n",
        "        min_arr[index] = min(temp[obs_ind])\n",
        "\n",
        "    for index, k in enumerate(cont_list):\n",
        "        observed_values[:, k] = (\n",
        "            (observed_values[:, k] - (min_arr[index] - 1))\n",
        "            / (max_arr[index] - min_arr[index] + 1)\n",
        "        ) * observed_masks[:, k]\n",
        "\n",
        "    # Get graph features\n",
        "    graph_values = observed_values * gt_masks\n",
        "    graph_features = [{component: np.array([bike[column_index[feature]] for feature in bike_components[component]], dtype=np.float32) for component in bike_components} for bike in graph_values]\n",
        "    print(\"graph features\", graph_features[0])\n",
        "\n",
        "    with open(\"./data/transformed_columns.pk\", \"wb\") as f:\n",
        "        pickle.dump([cont_list, num_cate_list], f)\n",
        "\n",
        "    with open(\"./data/encoder.pk\", \"wb\") as f:\n",
        "        pickle.dump(encoder, f)\n",
        "\n",
        "    with open(processed_data_path_norm, \"wb\") as f:\n",
        "        pickle.dump(\n",
        "            [observed_values, observed_masks, gt_masks, graph_features, max_arr, min_arr, train_index, test_index, valid_index], f\n",
        "        )\n",
        "    return observed_values, observed_masks, gt_masks, cont_list, graph_features, train_index, test_index, valid_index\n",
        "\n",
        "\n",
        "class tabular_Dataset(Dataset):\n",
        "    # eval_length should be equal to attributes number.\n",
        "    def __init__(self, masked_features, use_index_list=None, seed=0, missing_ratio=0):\n",
        "        np.random.seed(seed)\n",
        "        dataset_path = \"./new_colored_biked.csv\"\n",
        "\n",
        "        processed_data_path_norm = f\"./data/nfold-{nfold}-missing_ratio-{missing_ratio}_seed-{seed}_max-min_norm.pk\"\n",
        "        # self.cont_cols is only saved in .pk file before normalization.\n",
        "        if not os.path.isfile(processed_data_path_norm):\n",
        "            (\n",
        "                self.observed_values,\n",
        "                self.observed_masks,\n",
        "                self.gt_masks,\n",
        "                self.cont_cols,\n",
        "                self.graph_features,\n",
        "                self.train_index,\n",
        "                self.test_index,\n",
        "                self.valid_index,\n",
        "            ) = process_func(\n",
        "                dataset_path,\n",
        "                masked_features,\n",
        "                encode=True,\n",
        "                missing_ratio=missing_ratio,\n",
        "            )\n",
        "            print(\"--------Dataset created--------\")\n",
        "\n",
        "        elif os.path.isfile(processed_data_path_norm):  # load datasetfile\n",
        "            with open(processed_data_path_norm, \"rb\") as f:\n",
        "                self.observed_values, self.observed_masks, self.gt_masks, self.graph_features, _, _, self.train_index, self.test_index, self.valid_index = pickle.load(\n",
        "                    f\n",
        "                )\n",
        "            print(\"--------Normalized dataset loaded--------\")\n",
        "\n",
        "        if use_index_list is None:\n",
        "            self.use_index_list = np.arange(len(self.observed_values))\n",
        "        else:\n",
        "            self.use_index_list = use_index_list\n",
        "\n",
        "    def __getitem__(self, org_index):\n",
        "        index = self.use_index_list[org_index]\n",
        "        s = {\n",
        "            \"observed_data\": self.observed_values[index],\n",
        "            \"observed_mask\": self.observed_masks[index],\n",
        "            \"gt_mask\": self.gt_masks[index],\n",
        "            \"graph_features\": self.graph_features[index],\n",
        "            \"timepoints\": np.arange(timepoints),\n",
        "        }\n",
        "        return s\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.use_index_list)\n",
        "\n",
        "\n",
        "def get_dataloader(masked_features, seed=1, nfold=5, batch_size=16, missing_ratio=0):\n",
        "    dataset = tabular_Dataset(masked_features, seed=seed, missing_ratio=missing_ratio)\n",
        "    print(f\"Dataset size:{len(dataset)} entries\")\n",
        "\n",
        "    # Now the path exists, so the dataset object initialization performs data loading.\n",
        "    train_dataset = tabular_Dataset(\n",
        "        masked_features, use_index_list=dataset.train_index, missing_ratio=missing_ratio, seed=seed\n",
        "    )\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=1)\n",
        "\n",
        "    valid_dataset = tabular_Dataset(\n",
        "        masked_features, use_index_list=dataset.valid_index, missing_ratio=missing_ratio, seed=seed\n",
        "    )\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=0)\n",
        "\n",
        "    test_dataset = tabular_Dataset(\n",
        "        masked_features, use_index_list=dataset.test_index, missing_ratio=missing_ratio, seed=seed\n",
        "    )\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=0)\n",
        "\n",
        "    print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "    print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
        "    print(f\"Testing dataset size: {len(test_dataset)}\")\n",
        "\n",
        "    return train_loader, valid_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CECmAy_poWuv"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1eWX-Fnnn0C"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    model,\n",
        "    config,\n",
        "    train_loader,\n",
        "    valid_loader=None,\n",
        "    valid_epoch_interval=10,\n",
        "    foldername=\"\",\n",
        "  ):\n",
        "    # Control random seed in the current script.\n",
        "    torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    optimizer = Adam(model.parameters(), lr=config[\"lr\"], weight_decay=1e-6)\n",
        "    if foldername != \"\":\n",
        "        output_path = foldername + \"/model.pth\"\n",
        "\n",
        "    p0 = int(0.25 * config[\"epochs\"])\n",
        "    p1 = int(0.5 * config[\"epochs\"])\n",
        "    p2 = int(0.75 * config[\"epochs\"])\n",
        "    p3 = int(0.9 * config[\"epochs\"])\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer, milestones=[p0, p1, p2, p3], gamma=0.5\n",
        "    )\n",
        "    # history = {'train_loss':[], 'val_rmse':[]}\n",
        "    best_valid_loss = 1e10\n",
        "    model = model.to(device)\n",
        "    for epoch_no in range(config[\"epochs\"]):\n",
        "        avg_loss = 0\n",
        "        model.train()\n",
        "        with tqdm(train_loader, mininterval=5.0, maxinterval=50.0) as it:\n",
        "            for batch_no, train_batch in enumerate(it, start=1):\n",
        "                optimizer.zero_grad()\n",
        "                # The forward method returns loss.\n",
        "                loss = model(train_batch)\n",
        "                loss.backward()\n",
        "                avg_loss += loss.item()\n",
        "                optimizer.step()\n",
        "                it.set_postfix(\n",
        "                    ordered_dict={\n",
        "                        \"avg_epoch_loss\": avg_loss / batch_no,\n",
        "                        \"epoch\": epoch_no,\n",
        "                    },\n",
        "                    refresh=False,\n",
        "                )\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        if valid_loader is not None and (epoch_no + 1) % valid_epoch_interval == 0:\n",
        "            if foldername != \"\":\n",
        "              torch.save(model, output_path)\n",
        "            print(\"Start validation\")\n",
        "            model.eval()\n",
        "            avg_loss_valid = 0\n",
        "            # some initial settings\n",
        "            val_nsample = 15\n",
        "            val_scaler = 1\n",
        "            mse_total = 0\n",
        "            mae_total = 0\n",
        "            evalpoints_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with tqdm(valid_loader, mininterval=5.0, maxinterval=50.0) as it:\n",
        "                    for batch_no, valid_batch in enumerate(it, start=1):\n",
        "                        output = model.evaluate(valid_batch, val_nsample)\n",
        "                        # `eval_points` is `target_mask`. `observed_time` is `observed_tp`(10)\n",
        "                        # `c_target` is `observed_data`\n",
        "                        (\n",
        "                            samples,\n",
        "                            c_target,\n",
        "                            eval_points,\n",
        "                            observed_points,\n",
        "                        ) = output\n",
        "                        samples = samples.permute(0, 1, 3, 2)[:, :, config[\"model\"][\"graph_cond_dim\"]:, :]  # (B,nsample,L,K)\n",
        "                        c_target = c_target.permute(0, 2, 1)[:, config[\"model\"][\"graph_cond_dim\"]:, :]  # (B,L,K)\n",
        "                        eval_points = eval_points.permute(0, 2, 1)[:, config[\"model\"][\"graph_cond_dim\"]:, :]\n",
        "\n",
        "                        # take the median from samples.\n",
        "                        samples_median = samples.median(dim=1).values\n",
        "                        mse_current = (\n",
        "                            ((samples_median - c_target) * eval_points) ** 2\n",
        "                        ) * (val_scaler**2)\n",
        "                        mae_current = (\n",
        "                            torch.abs((samples_median - c_target) * eval_points)\n",
        "                        ) * val_scaler\n",
        "\n",
        "                        mse_total += torch.sum(mse_current, dim=0)\n",
        "                        evalpoints_total += torch.sum(eval_points, dim=0)\n",
        "\n",
        "                        it.set_postfix(\n",
        "                            ordered_dict={\n",
        "                                \"rmse_total\": torch.mean(\n",
        "                                    torch.sqrt(torch.div(mse_total, evalpoints_total))\n",
        "                                ).item(),\n",
        "                                \"batch_no\": batch_no,\n",
        "                            },\n",
        "                            refresh=True,\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03NspjAOxzeA"
      },
      "source": [
        "Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww4bbbw3x1SN"
      },
      "outputs": [],
      "source": [
        "def evaluate_ft(\n",
        "    model, test_loader, nsample=100, scaler=1, mean_scaler=0, foldername=\"\"\n",
        "  ):\n",
        "\n",
        "    with open(\"./data/transformed_columns.pk\", \"rb\") as f:\n",
        "        cont_list, num_cate_list = pickle.load(f)\n",
        "    with open(\"./data/encoder.pk\", \"rb\") as f:\n",
        "        encoder = pickle.load(f)\n",
        "\n",
        "    torch.manual_seed(0)\n",
        "    np.random.seed(0)\n",
        "    model = model.to(device)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        mse_total = 0\n",
        "        mae_total = 0\n",
        "        err_total = np.zeros([len(num_cate_list)])\n",
        "        err_total_eval_nums = np.zeros([len(num_cate_list)])\n",
        "        evalpoints_total = 0\n",
        "\n",
        "        all_target = []\n",
        "        all_observed_point = []\n",
        "        all_evalpoint = []\n",
        "        all_generated_samples = []\n",
        "\n",
        "        with tqdm(test_loader, mininterval=5.0, maxinterval=50.0) as it:\n",
        "            for batch_no, test_batch in enumerate(it, start=1):\n",
        "                output = model.evaluate(test_batch, nsample)\n",
        "                samples, c_target, eval_points, observed_points = output\n",
        "                samples = samples.permute(0, 1, 3, 2)  # (B,nsample,L,K)\n",
        "                c_target = c_target.permute(0, 2, 1)  # (B,L,K)\n",
        "                eval_points = eval_points.permute(0, 2, 1)\n",
        "                observed_points = observed_points.permute(0, 2, 1)\n",
        "\n",
        "                # take the median from samples.\n",
        "                samples_median = samples.median(dim=1)  # (B, L, K)\n",
        "\n",
        "                samples_median = model.tokenizer.recover(\n",
        "                    samples_median.values, len(cont_list)\n",
        "                )\n",
        "\n",
        "                c_target = model.tokenizer.recover(c_target, len(cont_list))\n",
        "                all_target.append(c_target)\n",
        "                all_evalpoint.append(eval_points)\n",
        "                all_observed_point.append(observed_points)\n",
        "                all_generated_samples.append(samples)\n",
        "\n",
        "                # for continous variables\n",
        "                mse_current = (\n",
        "                    (\n",
        "                        (samples_median[:, cont_list] - c_target[:, cont_list])\n",
        "                        * eval_points[:, cont_list, 0]\n",
        "                    )\n",
        "                    ** 2\n",
        "                ) * (scaler**2)\n",
        "                mae_current = (\n",
        "                    torch.abs(\n",
        "                        (samples_median[:, cont_list] - c_target[:, cont_list])\n",
        "                        * eval_points[:, cont_list, 0]\n",
        "                    )\n",
        "                ) * scaler\n",
        "\n",
        "                # for categorical variables\n",
        "                for i in range(len(num_cate_list)):\n",
        "                    matched_nums = (\n",
        "                        samples_median[:, len(cont_list) + i]\n",
        "                        == c_target[:, len(cont_list) + i]\n",
        "                        * eval_points[:, len(cont_list) + i, 0]\n",
        "                    ).sum()\n",
        "                    eval_nums = eval_points[:, len(cont_list) + i, 0].sum()\n",
        "                    err_total[i] += eval_nums - matched_nums\n",
        "                    err_total_eval_nums[i] += eval_nums\n",
        "\n",
        "                mse_total += torch.sum(mse_current, dim=0)\n",
        "                mae_total += torch.sum(mae_current, dim=0)\n",
        "                evalpoints_total += torch.sum(eval_points[:, cont_list, 0], dim=0)\n",
        "                it.set_postfix(\n",
        "                    ordered_dict={\n",
        "                        \"rmse_total\": torch.mean(\n",
        "                            torch.sqrt(torch.div(mse_total, evalpoints_total))\n",
        "                        ).item(),\n",
        "                        \"batch_no\": batch_no,\n",
        "                    },\n",
        "                    refresh=True,\n",
        "                )\n",
        "\n",
        "            with open(foldername + \"/result_nsample\" + str(nsample) + \".pk\", \"wb\") as f:\n",
        "                pickle.dump(\n",
        "                    [\n",
        "                        torch.mean(\n",
        "                            torch.sqrt(torch.div(mse_total, evalpoints_total))\n",
        "                        ).item(),\n",
        "                        err_total / err_total_eval_nums,\n",
        "                    ],\n",
        "                    f,\n",
        "                )\n",
        "                print(\n",
        "                    \"RMSE:\",\n",
        "                    torch.mean(\n",
        "                        torch.sqrt(torch.div(mse_total, evalpoints_total))\n",
        "                    ).item(),\n",
        "                )\n",
        "                print(\"ERR_CATE:\", err_total / err_total_eval_nums)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA513Sqjppv5"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvedK_xJCJA7",
        "outputId": "ebcc4b5b-994e-4985-9948-fbfc951a9cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'BB textfield': 0, 'Seat tube length': 1, 'Stack': 2, 'Head tube upper extension2': 3, 'Seat angle': 4, 'CS textfield': 5, 'FCD textfield': 6, 'Seat tube extension2': 7, 'Head tube lower extension2': 8, 'Head angle': 9, 'Saddle height': 10, 'ERD rear': 11, 'Wheel width rear': 12, 'Dropout spacing': 13, 'SPOKES composite front': 14, 'SPOKES front': 15, 'Wheel diameter front': 16, 'BSD front': 17, 'Wheel diameter rear': 18, 'SPOKES rear': 19, 'Wheel width front': 20, 'SPOKES composite rear': 21, 'ERD front': 22, 'BSD rear': 23, 'SBLADEW front': 24, 'SBLADEW rear': 25, 'FORK0R': 26, 'FORK0L': 27, 'Saddle P': 28, 'Saddle thickness': 29, 'Saddle angle': 30, 'Saddle J': 31, 'Saddle H': 32, 'Saddle E': 33, 'SADDLETIPtoMIDDLE': 34, 'Saddle length': 35, 'Seatpost setback': 36, 'Seatpost LENGTH': 37, 'Lower stack height': 38, 'Upper stack height': 39, 'Headset spacers': 40, 'Stem angle': 41, 'CLAMPOFFSET': 42, 'StemX': 43, 'StemY': 44, 'StemG': 45, 'Collar height': 46, 'Stem length': 47, 'AEROF': 48, 'Hand horizontal': 49, 'Pad vertical': 50, 'Hand vertical': 51, 'MtnBar angle': 52, 'Mountain bar sweep': 53, 'MTNDROP': 54, 'HBARTHETA': 55, 'Mountain bar rise': 56, 'Handlebar angle': 57, 'Bullhorn reach': 58, 'BULLTHETA': 59, 'Road bar reach': 60, 'BULLRADIUS2': 61, 'Road bar drop': 62, 'Brake lever position': 63, 'Bullhorn drop': 64, 'Bullhorn rise': 65, 'Bullhorn angle': 66, 'HBAREXTEND': 67, 'HBARRAD1': 68, 'HBARRAD2': 69, 'Down tube front diameter': 70, 'Down tube rear dia2': 71, 'Down tube front dia2': 72, 'Down tube rear diameter': 73, 'Seat tube leading edge textfield': 74, 'BB length': 75, 'Seat tube chord length textfield': 76, 'Top tube rear diameter': 77, 'Down tube leading edge': 78, 'Head tube diameter': 79, 'DOWNTUBE Wheel cut': 80, 'Wheel cut': 81, 'Down tube aero diameter': 82, 'Top tube rear dia2': 83, 'Top tube front dia2': 84, 'BB diameter': 85, 'Head tube chord': 86, 'Seat tube diameter': 87, 'OFFSET_AT_BB st': 88, 'Top tube front diameter': 89, 'Head tube d': 90, 'Head tube B': 91, 'Head tube E': 92, 'Head tube D': 93, 'OFFSET_AT_BB dt': 94, 'CHAINSTAYOFFSET': 95, 'CHAINSTAYAUXrearDIAMETER': 96, 'Chain stay horizontal diameter': 97, 'Chain stay position on BB': 98, 'Chain stay taper': 99, 'Chain stay back diameter': 100, 'Chain stay vertical diameter': 101, 'CHAINSTAYbrdgdia1': 102, 'CHAINSTAYbrdgshift': 103, 'Seat stay junction0': 104, 'Seat stay bottom diameter': 105, 'SEATSTAY_HF': 106, 'SSTopZOFFSET': 107, 'SEATSTAY_HR': 108, 'SEATSTAYTAPERLENGTH': 109, 'SEATSTAYbrdgdia1': 110, 'SEATSTAYbrdgoffset': 111, 'bottle SEATTUBE0 WBX': 112, 'bottle SEATTUBE0 WBY': 113, 'bottle DOWNTUBE0 X': 114, 'bottle DOWNTUBE0 WBY': 115, 'bottle DOWNTUBE0 WBX': 116, 'bottle SEATTUBE0 X': 117, 'Front Fender clearance': 118, 'Front fender end angle': 119, 'Rear fender end angle': 120, 'Fender clearance': 121, 'Rear fender start angle': 122, 'Front fender start angle': 123, 'FDDIST': 124, 'SPIDER_DIAMETER': 125, 'Crank length': 126, 'Number of cogs': 127, 'Crank Q factor': 128, 'PEDAL_LENGTH': 129, 'Teeth on cog 2': 130, 'Teeth on cog 3': 131, 'Teeth on cog 4': 132, 'Teeth on cog 5': 133, 'Teeth on cog 6': 134, 'Teeth on cog 7': 135, 'Teeth on cog 8': 136, 'Teeth on cog 9': 137, 'Pedal width': 138, 'Teeth on cog 10': 139, 'Teeth on chainring 0': 140, 'Teeth on chainring 1': 141, 'Teeth on chainring 2': 142, 'CassZ': 143, 'CassT': 144, 'CassA': 145, 'Teeth on cog 11': 146, 'BACKGROUND color R_RGB': 147, 'BACKGROUND color G_RGB': 148, 'BACKGROUND color B_RGB': 149, 'SAME_SIZED_FRONT_AND_REAR': 150, 'Display AEROBARS': 151, 'HBARRISE': 152, 'Bullhorn risy': 153, 'CHAINSTAYbrdgCheck': 154, 'bottle SEATTUBE0 CAGE': 155, 'bottle DOWNTUBE0 CAGE': 156, 'Front Fender include': 157, 'Rear Fender include': 158, 'Number of chainrings': 159, 'Display RACK': 160, 'Dropout spacing style': 161, 'RIM_STYLE front': 162, 'RIM_STYLE rear': 163, 'Fork type': 164, 'HEADSETprofile': 165, 'Stem kind': 166, 'Aerobar style': 167, 'Brake lever brand': 168, 'Handlebar style': 169, 'TRACK_ERGO': 170, 'Head tube type': 171, 'Seat tube type': 172, 'Top tube type': 173, 'bottle SEATTUBE0 show': 174, 'bottle DOWNTUBE0 show': 175, 'BELTorCHAIN': 176, 'MOUNT_TYPE': 177, 'BRAZEonFDTYPE': 178, 'DIRECTMOUNTFDTYPE': 179, 'CLAMPFDTYPE': 180, 'spc type': 181}\n",
            "--------------Dataset has not been normalized yet. Perform data normalization and store the mean value of each column.--------------\n",
            "graph features {'Seat Tube': array([0.62112916, 0.21244289, 0.24822696, 0.        , 0.4293866 ,\n",
            "       0.4114386 , 0.32666665, 0.70625   ], dtype=float32), 'Head Tube': array([0.        , 0.7638889 , 0.76683176, 0.5394737 ], dtype=float32), 'Top Tube': array([0.205298  , 0.18103448], dtype=float32), 'Down Tube': array([0.32824427, 0.26109093], dtype=float32), 'Chain Stay': array([0.05980067, 0.00286486, 0.00179998, 0.3344426 , 0.16216215,\n",
            "       0.27657658], dtype=float32), 'Seat Stay': array([0.5285714 , 0.10687023, 0.07171315, 0.14893617, 0.22308546],\n",
            "      dtype=float32), 'Fork': array([0.09866017, 0.34336168], dtype=float32), 'Saddle': array([0.43127963, 0.69135803, 0.12958436, 0.25925925, 0.375     ,\n",
            "       0.34545454, 0.6385542 , 0.24108416], dtype=float32), 'Wheel': array([0.        , 0.17629775, 0.34905082, 0.30203545, 0.18181819,\n",
            "       0.        , 0.3809524 , 0.18181819, 0.35057124, 0.35057124],\n",
            "      dtype=float32), 'Handle': array([0.44444445, 0.6515151 , 0.43564355, 0.52554744, 0.2631579 ,\n",
            "       0.18817204, 0.        , 0.36819172, 0.3482587 , 0.2985972 ,\n",
            "       0.7761791 ], dtype=float32), 'BB': array([0.67666465, 0.00974439, 0.45054945], dtype=float32)}\n",
            "--------Dataset created--------\n",
            "Dataset size:124511 entries\n",
            "--------Normalized dataset loaded--------\n",
            "--------Normalized dataset loaded--------\n",
            "--------Normalized dataset loaded--------\n",
            "Training dataset size: 123265\n",
            "Validation dataset size: 0\n",
            "Testing dataset size: 1246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "  0%|          | 0/309 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "train_loader, valid_loader, test_loader = get_dataloader(\n",
        "    masked_features,\n",
        "    seed=seed,\n",
        "    nfold=nfold,\n",
        "    batch_size=config[\"train\"][\"batch_size\"],\n",
        "    missing_ratio=config[\"model\"][\"test_missing_ratio\"],\n",
        ")\n",
        "\n",
        "model = BikeGraphCSDI(config, device)\n",
        "\n",
        "foldername = \"./save/BikeGraphCSDI/\"\n",
        "\n",
        "train(\n",
        "    model,\n",
        "    config[\"train\"],\n",
        "    train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    foldername=foldername,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Lj1EE9_fVKM"
      },
      "outputs": [],
      "source": [
        "evaluate_ft(model, train_loader, nsample=nsample, scaler=1, foldername=foldername)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyD0kY5-Laa0"
      },
      "source": [
        "Qualitative Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9PYzcPa6LaIU"
      },
      "outputs": [],
      "source": [
        "num_sam = 5   # number of samples\n",
        "num_sim = 150   # number of diffusion simulations\n",
        "masked_features = [\"Stem angle\", \"Seat tube length\", \"bottle SEATTUBE0 show\", \"Handlebar style\"]\n",
        "\n",
        "_, _, test_loader = get_dataloader([], seed=4096, batch_size=num_sam * len(masked_features), nfold=10, missing_ratio=0)\n",
        "test_index = test_loader.dataset.test_index\n",
        "\n",
        "model = torch.load(\"./save/BikeGraphCSDI/model.pth\", map_location=device).to(device)\n",
        "model.device = device\n",
        "model.graph_embed.device = device\n",
        "\n",
        "with open(\"column_index.pk\", \"rb\") as f:\n",
        "  column_index = pickle.load(f)\n",
        "\n",
        "test_loader.dataset.gt_masks = np.ones_like(test_loader.dataset.gt_masks)\n",
        "for n, i in enumerate(masked_features):\n",
        "  test_loader.dataset.gt_masks[test_loader.dataset.use_index_list[num_sam*n:num_sam*(n+1)], column_index[i]] = False  # Manual mask\n",
        "\n",
        "sample, _, _, _ = model.evaluate(next(iter(test_loader)), num_sim)\n",
        "sample = sample.permute(0, 1, 3, 2)\n",
        "\n",
        "with open(\"./data/transformed_columns.pk\", \"rb\") as f:\n",
        "    cont_list, num_cate_list = pickle.load(f)\n",
        "with open(\"./data/encoder.pk\", \"rb\") as f:\n",
        "    encoder = pickle.load(f)\n",
        "\n",
        "num_feature = len(cont_list) + len(num_cate_list)\n",
        "\n",
        "temp = torch.zeros(len(masked_features) * num_sam * num_sim, num_feature)\n",
        "for i in range(len(masked_features) * num_sam):\n",
        "  for j in range(num_sim):\n",
        "    temp[i*(num_sim)+j,:] = model.tokenizer.recover(sample[i,j,:,:].unsqueeze(0), len(cont_list))[0]\n",
        "\n",
        "with open(\"./data/nfold-10-missing_ratio-0.1_seed-4096_max-min_norm.pk\", \"rb\") as f:\n",
        "  _, _, _, _, max_arr, min_arr, _, _, _ = pickle.load(f)\n",
        "\n",
        "for i in cont_list:   # Recover from normalization\n",
        "  temp[:, i] *= (max_arr[i] - min_arr[i] + 1)\n",
        "  temp[:, i] += min_arr[i] - 1\n",
        "\n",
        "data = pd.read_csv(\"new_colored_biked.csv\", header=0)\n",
        "data = data.iloc[:, 1:]\n",
        "\n",
        "ref = (pd.read_csv(\"new_colored_biked_processed.csv\", header=0).iloc[:, 1:]).columns\n",
        "first_cat = 0\n",
        "for n, i in enumerate(ref):\n",
        "  if \"OHCLASS:\" in i:\n",
        "    first_cat = n\n",
        "    break\n",
        "\n",
        "for n, i in enumerate(masked_features):   # Save the local table with truth, masked and generated\n",
        "  df = pd.DataFrame(np.repeat(data.values[test_index[n*num_sam:(n+1)*num_sam]],num_sim,axis=0))\n",
        "  df.columns = data.columns\n",
        "  df.to_csv(\"truth_{}.csv\".format(i))\n",
        "  df_dum = pd.get_dummies(df, prefix_sep=\" OHCLASS: \", columns=df.columns[first_cat:])  # Convert back to one hot encoding\n",
        "  for c in ref:\n",
        "    if c not in df_dum.columns:\n",
        "      df_dum[c] = 0\n",
        "  df_dum.to_csv(\"truth_{}_OH.csv\".format(i))\n",
        "  df[i] = pd.NA\n",
        "  df.to_csv(\"masked_{}.csv\".format(i))\n",
        "\n",
        "  for c in df_dum.columns:\n",
        "    if i in c:\n",
        "      df_dum[c] = pd.NA\n",
        "  df_dum.to_csv(\"masked_{}_OH.csv\".format(i))\n",
        "  df = encoder.transform(df)\n",
        "  df[i] = temp[num_sam * num_sim * (n): num_sam * num_sim * (n+1), column_index[i]]\n",
        "  df = encoder.inverse_transform(df)\n",
        "  df.to_csv(\"generated_{}.csv\".format(i))\n",
        "  df_dum = pd.get_dummies(df, prefix_sep=\" OHCLASS: \", columns=df.columns[first_cat:])\n",
        "  for c in ref:\n",
        "    if c not in df_dum.columns:\n",
        "      df_dum[c] = 0\n",
        "  df_dum.to_csv(\"generated_{}_OH.csv\".format(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKtHPs9oSWkF"
      },
      "outputs": [],
      "source": [
        "def compare_plot(population, feature, who=0, type=\"cont\", num_sim=150):\n",
        "  truth = pd.read_csv(\"truth_{}.csv\".format(feature)).loc[who*num_sim:(who+1)*num_sim]\n",
        "  generated = pd.read_csv(\"generated_{}.csv\".format(feature)).loc[who*num_sim:(who+1)*num_sim]\n",
        "  if type == \"cont\":\n",
        "    plt.hist(population[feature], bins=50, alpha=0.5, label='truth', density=True)\n",
        "    plt.hist(generated[feature], alpha=0.5, label='generated', density=True)\n",
        "    plt.axvline(x=truth[feature][who*num_sim], ymin=0, ymax=0.1)\n",
        "    plt.axvline(x=generated[feature].mean() + bias, color=\"red\", ymin=0, ymax=0.1)\n",
        "    plt.title(feature)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "  else:\n",
        "    labels = set(population[feature])\n",
        "    truth = np.array([sum([row[feature]==label for _, row in truth.iterrows()]) for label in labels])\n",
        "    truth = truth / (truth.sum())\n",
        "    generated = np.array([sum([row[feature]==label for _, row in generated.iterrows()]) for label in labels])\n",
        "    generated = generated / (generated.sum())\n",
        "\n",
        "    x = np.arange(len(labels))  # the label locations\n",
        "    width = 0.35  # the width of the bars\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    rects1 = ax.bar(x - width/2, truth, width, label='truth')\n",
        "    rects2 = ax.bar(x + width/2, generated, width, label='generated')\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_title(feature)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tS4MFbeTRqV"
      },
      "outputs": [],
      "source": [
        "population = pd.read_csv(\"new_colored_biked.csv\", header=0).iloc[:,1:]\n",
        "feature = \"Stem angle\"\n",
        "compare_plot(population, feature, who=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39dWSj1YTXzh"
      },
      "outputs": [],
      "source": [
        "feature = \"Seat tube length\"\n",
        "compare_plot(population, feature, who=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjIQ53-tTiP5"
      },
      "outputs": [],
      "source": [
        "feature = \"bottle SEATTUBE0 show\"\n",
        "compare_plot(population, feature, type=\"cat\", who=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bINKr-uUFKuH"
      },
      "outputs": [],
      "source": [
        "feature = \"Handbar style\"\n",
        "compare_plot(population, feature, type=\"cat\", who=3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}